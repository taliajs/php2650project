---
title: "Bayesian Neural Networks" 
output: 
  md_document:  
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#setwd("C:/Users/tjses/OneDrive/Documents/Spring 2023/PHP 2650 - Big Data/Final Project/php2650project")
```

# Applying Bayesian Inference into Neural Networks

Deep learning is a machine learning technique used for learning neural networks, and for processing data in a more “human” way. Deep Learning Neural Networks are a powerful tool that can be used to approximate solutions to many functions, even if they are not closed form. However, a major problem with neural networks is overfitting, which is when the learning algorithm does such a good job of tuning the parameters on the training set that it performs badly on new data [1]. There are many methods that can be used to reduce overfitting (like early stopping or dropout), but the method we are focusing on is **applying Bayesian inference into the neural network**. 


## Bayesian

The Bayesian paradigm is based on 2 simple ideas: 1) Probability is a measure of belief in the occurrence of events, rather than the limit in the frequency of occurrence (when the number of samples goes to infinity), which is assumed in the frequentist paradigm. 2) Prior beliefs influence posterior probabilities, also known as Bayes theorem [2]. 

## Bayesian Neural Networks (BNNs)

Bayesian inference allows us to learn a probability distribution over possible neural networks [1, which can not only reduce overfitting, but inform us on how much uncertainty the model has. 

Bayesian neural networks are neural networks that are trained using a Bayesian approach [2], meaning that the neural network has a prior on its weights [3]. BNNs are a promising paradigm that allows the generalization of applying deep learning in areas where a system is not allowed to fail [2]. These networks are about modeling uncertainty in parameters [2]. By modeling uncertainty, BNNs provides better prediction accuracy under the same model, and provides better uncertainty estimation for a predictive distribution [3]. BNNs are useful in active learning (human or algorithm labels new points from an unlabeled dataset) and online learning (where a model is retrained as new data becomes available) [2]. 

Normally, a neural networks aims to use the training data 


my\_stock\_ticker

$3\sb{x}$


<img src="https://render.githubusercontent.com/render/math?math=e^{i \pi} = -1">


## References

1. Yu, et al. Bayesian Neural Networks. https://www.cs.toronto.edu/~duvenaud/distill_bayes_net/public/

2. Jospin et al (2022). Hands-on Bayesian Neural Networks – A Tutorial for Neural Deep Learning Methods. Machine Learning.IEEE Computational Intelligence Magazine 17(2): 29-48

3. Bayesian Deep Learning [slides]: https://alinlab.kaist.ac.kr/resource/Lec8_Bayesian_DL.pdf
